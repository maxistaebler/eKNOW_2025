Iterative rejection sampling, which is a method used to refine predictions by iteratively selecting and discarding incorrect responses, has shown mixed results across different datasets. Specifically, it improves performance on the 2WikiMultihopQA dataset but degrades performance on other datasets.

In the context of 2WikiMultihopQA, iterative rejection sampling likely works well because this dataset involves complex multi-hop reasoning tasks that require the model to integrate information from multiple sources. The iterative process can help filter out incorrect intermediate steps, thereby leading to more accurate final answers (Data: Relationships (18; 594)). However, on other datasets where the structure of questions or the nature of the data is different, this method may not be as effective. For example, on simpler datasets with less complex reasoning requirements, iterative rejection sampling might over-correct and introduce errors that degrade overall performance (Data: Relationships (18; 594)).

This variability in results across different datasets suggests that there are diminishing returns in the quality of chain-of-thought reasoning as indicated by iterative rejection sampling. The method performs best on problems where multi-step reasoning is necessary, but its effectiveness diminishes or even becomes harmful when applied to simpler tasks (Data: Relationships (18; 594)).

In summary, the observed improvement on 2WikiMultihopQA and degradation on other datasets point to potential limitations in how iterative rejection sampling handles different levels of complexity. This indicates that further refinement may be necessary for this method to consistently improve performance across a wide range of tasks (Data: Relationships (18; 594)).