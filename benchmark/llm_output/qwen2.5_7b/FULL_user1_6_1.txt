Iterative Rejection Sampling (IRS) is an approach used to improve the accuracy of predictions by iteratively refining them, often through multiple passes or iterations over a dataset. In the context of 2WikiMultihopQA and other datasets, different results might be observed due to several factors:

1. **Dataset Characteristics**:
   - **2WikiMultihopQA**: This dataset likely involves complex question-answering tasks that require multiple hops (queries) through linked information sources like Wikipedia. Iterative refinement can help in navigating these multi-hop paths more effectively, improving the overall quality of answers.
   - Other datasets might not have such intricate relationships between questions and answers, which could make IRS less beneficial or even detrimental if it introduces unnecessary complexity.

2. **Model Performance**:
   - The impact of iterative rejection sampling might vary depending on the performance characteristics of the underlying model. In some cases, models might already be performing well enough that additional refinement via IRS doesn't offer significant benefits and can sometimes introduce noise.
   
3. **Overfitting Risk**:
   - Iterative methods like IRS can lead to overfitting if not properly controlled. While they are designed to improve accuracy, the repeated processing of data points can sometimes memorize the training set rather than generalizing well.

4. **Computational Cost and Complexity**:
   - The computational overhead of iterative sampling could be significant, especially on larger datasets or with more complex models. For some simpler or less computationally demanding tasks, this added complexity might not justify the benefits.
   
5. **Quality of Chains**:
   - If IRS introduces diminishing returns in chain quality (chains of information or reasoning steps), it can degrade overall performance. This could happen if the iterative process is adding noise or incorrect intermediate steps to the reasoning chains.

### Diminishing Returns and Chain Quality

The observation that iterative rejection sampling improves 2WikiMultihopQA but degrades other datasets might indeed suggest diminishing returns in chain quality, depending on how the iterations are implemented:

- **Improvement**: For complex tasks where multiple hops or chains of reasoning are necessary (like in 2WikiMultihopQA), IRS can help by refining and verifying each step. If done carefully, it can enhance the accuracy and robustness of the answers.
  
- **Degradation**: On simpler datasets with fewer hops or more straightforward relationships between questions and answers, IRS might introduce unnecessary complexity. If not managed properly, it could lead to overly complex chains that are harder to verify and less reliable.

### Recommendations

To mitigate potential issues:

1. **Thresholding**: Implement a threshold for the number of iterations or the confidence required before stopping.
2. **Cross-validation**: Use cross-validation techniques to ensure that IRS doesn't overfit to the training data.
3. **Model Complexity**: Ensure that the model complexity aligns with the task requirements, so iterative refinement adds value without introducing unnecessary overhead.

In summary, the varying performance of iterative rejection sampling across different datasets might indeed indicate diminishing returns in chain quality and highlights the importance of carefully tuning and managing such iterative processes.