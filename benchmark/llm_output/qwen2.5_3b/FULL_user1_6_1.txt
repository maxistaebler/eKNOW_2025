Iterative rejection sampling is an algorithm used to generate samples from a probability distribution, particularly when direct sampling is difficult or inefficient. In the context of QA (Question Answering) systems like 2WikiMultihopQA, it can be applied to refine and improve the accuracy and relevance of answers by iteratively refining the sampling process based on previous attempts.

When discussing how iterative rejection sampling affects different datasets, there are several factors at play:

1. **Complexity and Structure**: Different QA datasets have varying complexities and structures. Some may involve more nuanced or intricate reasoning paths that iterative refinement can capture better, hence showing improvement. Other datasets might be simpler in structure or cover a wider range of questions which could make iterative sampling less effective.

2. **Quality and Noise Levels**: The quality and the amount of noise (unreliable answers) present in the dataset also play crucial roles. Iterative rejection sampling often benefits from noisy data, as it can help filter out low-quality samples over multiple iterations. Datasets with high levels of noise might see less improvement or even degradation if iterative methods become more prone to false positives.

3. **Relevance and Diversity**: Some datasets may have a higher degree of relevance or diversity in their questions and answers which could lead to better performance improvements from iterative refinement, whereas others might not benefit as much due to lower inherent quality or variance.

4. **Algorithm Adaptation**: The effectiveness of iterative rejection sampling can also depend on how well the algorithm is adapted to each dataset's characteristics. Different datasets may require different levels of complexity and sophistication in their sampling processes for optimal performance improvements.

Regarding your question about whether this indicates "diminishing returns in chain quality", it seems like a reasonable assumption, but it depends on the specific context and analysis of each dataset. Diminishing returns generally refer to situations where adding more iterations (or effort) results in less noticeable or marginal gains. If iterative rejection sampling does improve QA systems on 2WikiMultihopQA but degrades other datasets, this could suggest different levels of "chain quality" across those datasets.

For instance:
- **2WikiMultihopQA**: The system might be better equipped to handle the complexity and nuances of multihop reasoning questions.
- **Other Datasets**: These datasets might have simpler structures or less variation in question types that make iterative refinement less effective.

To conclude, while the observed behavior suggests some form of diminishing returns in terms of performance improvements when applying iterative rejection sampling across different datasets, it is more nuanced and depends on factors specific to each dataset.